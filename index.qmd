---
title: "Exam-01"
author: "Pablo Vivas"
date: "`r Sys.Date()`"
format:
  html:
    toc: true
    toc-location: left
    toc-depth: 1
    code-copy: true
    code-fold: true
    highlight-style: nord
  docx: default
execute:
  warning: false
  error: false
  echo: true
theme: simplex
---

```{r}
#| label: set-up
#| echo: false

library(broom)
library(cowplot)
library(ggrepel)
library(gt)
library(skimr)
library(patchwork)
library(tidyverse)
```

# Question 1

## Descriptive analysis

First, we read the data and take a look at some observations.

```{r}
#| label: tbl-read-data
#| tbl-cap: Sample of (n=10) observations of the World data 

world = read_csv("data/world-3.csv")

world |> 
  sample_n(10) |> 
  arrange(country) |> 
  gt() |> 
  fmt_number(
    columns = c(6, 10, 11, 12),
    decimals = 2
  )
```

Then, we make a description of all the numeric values.

```{r}
#| label: tbl-desc-data
#| tbl-cap: Summary of numeric variables for the World data 

world |> 
  select(where(is.numeric)) |> 
  skim() |> 
  select(-1) |> 
  arrange(skim_variable) |> 
  gt() |> 
  fmt_number(
    columns = 3:10,
    decimals = 2
  ) |> 
  cols_label(
    skim_variable = "variable",
    n_missing = "missing",
    numeric.mean = "mean",
    numeric.sd = "std",
    numeric.p0 = "p0",
    numeric.p25 = "p25",
    numeric.p50 = "p50",
    numeric.p75 = "p75",
    numeric.p100 = "p100",
    numeric.hist = "histogram"
  ) |> 
  cols_align(
    columns = -1,
    align = "center"
  )
```

We see from @tbl-desc-data that some of the variables have missing data, specifically, the `literacym` and the `literacyf` variables have complete rate of 78%. Also, the standard deviation from each variable is in a different scale, ranging from 0.62 units in `gdp` to 38.08 units in `babymort`. This makes sense because some variables are in a log-scale.

::: callout-note
Given this scenario of differences between scales and variability, we would prefer to perform the principal component analysis with the correlation matrix instead of the covariance matrix.
:::

### a)

We perform two principal component analysis using: a) the covariance matrix and b) the correlation matrix.

```{r}
#| label: pca-perform

# get complete cases
world_complete = world |> 
  drop_na()

# for the covariance matrix
pca_cov = world_complete |> 
  select(-c(1,2)) |> 
  prcomp()

# for the correlation matrix
pca_cor = world_complete |> 
  select(-c(1,2)) |> 
  prcomp(scale = TRUE)
```

We plot the differences for the two analysis using each method. The plots will contain the first two principal components.

```{r}
#| label: fig-plot-comparison
#| fig-cap: "Plot of principal component loadings for the first two pcs using the covariance matrix (left) and the correlation matrix (right)"
#| fig-width: 13
#| fig-height: 5

data_p01 = tibble(var = colnames(world_complete)[-c(1,2)], pca_1 = pca_cov$rotation[,1], pca_2 = pca_cov$rotation[,2]) 

data_p02 = tibble(var = colnames(world_complete)[-c(1,2)], pca_1 = pca_cor$rotation[,1], pca_2 = pca_cor$rotation[,2]) 

p01 = data_p01 |> 
  ggplot(aes(x = pca_1, y = pca_2, label= var)) +
  geom_point(size = 4, color = "red") +
  geom_label_repel(size = 4) +
  xlim(c(-0.65, 0.50)) +
  ylim(c(-0.65, 0.65)) +
  xlab("PC1 (cov)") +
  ylab("PC2 (cov)") +
  theme_classic()

p02 = data_p02 |> 
  ggplot(aes(x = pca_1, y = pca_2, label= var)) +
  geom_point(size = 4, color = "red") +
  geom_label_repel(size = 4) +
  xlim(c(-0.65, 0.50)) +
  ylim(c(-0.65, 0.65)) +
  xlab("PC1 (cor)") +
  ylab("PC2 (cor)") +
  theme_classic()

p01 | p02 
```

Based on the results presented on @fig-plot-comparison we can conclude that the loadings across the two solutions differ (although the plot only presented the first two components for each solution, the same behavior, or a lesser extent of it, is observed on the remainder of the components). The right plot shows that the variables related to `literacy` have larger values on the first and second principal component than the other variables (except for `babymort` in the second component). This behavior matches the difference in standard deviation we see in @tbl-desc-data. On the other hand, the left plot shows a more distributed pattern of the loadings, where no variable stands out from the rest. The difference between the loadings across the two solutions can be explain by the scale-dependency of the technique. Given this difference, I think it is more appropriate to analyze this dataset with the *correlation matrix*.

### b)

To investigate the number of necessary principal components to adequately describe the variability among the variables, several approaches will be taken.

1.  Scree-plot & Kaiser rule

```{r}
#| label: fig-scree-plot
#| fig-cap: Scree plot and Kaiser rule (dotted red line)
#| fig-width: 9
#| fig-height: 5

pca_cor |> 
  tidy(matrix = "eigenvalues") |> 
  mutate(lambda = std.dev * std.dev) |> 
  ggplot(aes(PC, lambda)) +
  geom_col(fill = "#56B4E9", alpha = 0.8) +
  geom_abline(slope =  0, intercept = 1, linetype = "dashed", color = "red") +
  xlab("PCA") +
  scale_x_continuous(breaks = 1:13) +
  scale_y_continuous(
       expand = expansion(mult = c(0, 0.01))
    ) +
  theme_minimal_hgrid(12)
```

The scree plot suggests that we need to extract two principal components, because at pca number 3 we notice the "elbow" in the amount of variance explained. After the second component, the remainder principal components account for a negligible amount of variance. Plus, the Kaiser rule also suggest that we need to extract two principal components because only the first two have an eigenvalue greater than one.

2.  Proportion of explained variance.

```{r}
#| label: tbl-percentage
#| tbl-cap: Proportion of variance explained (raw and cummulative) for each principal component (PC)

pca_cor |> 
  tidy(matrix = "eigenvalues") |>
  mutate(per = round(percent * 100, 2),
         per.cum = round(cumulative * 100, 2),
         .keep = "unused") |> 
  select(-std.dev) |> 
  gt() |> 
  cols_width(
    per ~ px(120),
    per.cum ~ px(120)
  ) |>
  cols_label(
    per = "Percentage",
    per.cum = "Cummulative"
  ) |> 
  cols_align(
    columns = -1,
    align = "center"
  )
```

Based on @tbl-percentage, the analysis indicates that two principal components explain over a 80% of the variance. Even thought is subjective, I believe that this percentage is good enough for this context. Also, two components explaining over a 80% in this analysis with 13 variables is acceptable/awesome 😁.

::: callout-note
The three methods (scree-plot, Kaiser rule and proportion of variance explained) suggest that 2 principal components appear to be necessary to describe adequately the variability in these variables. The rest of the analysis will be done using two principal components.
:::

### c)

In order to make interpretations of the two principal components, we will take a look at the loadings:

```{r}
#| label: tbl-loadings-cor
#| tbl-cap: Loading of the first two principal components

data_p02 |> 
  gt() |> 
  cols_width(
    everything() ~ px(150)
  ) |> 
  cols_align(
    columns = -1,
    align = "center"
  ) |> 
  fmt_number(
    columns = 2:3,
    decimals = 2
  ) |> 
  cols_label(
    var = "Variable",
    pca_1 = "PC1",
    pca_2 = "PC2"
  )
```
Based on @tbl-loadings-cor and its graphical representation in @fig-plot-comparison (right plot) we can interpret each principal component as follows:

- *Principal Component 1:* This component seems to be associated with general or overall development indicators. High positive scores on PC1 correlate with high GDP, high literacy rates (for both males and females), and higher life expectancy for both males and females. This suggests that countries with higher scores on PC1 are likely to be more developed, with stronger economies and better health and education systems. On the other hand, countries with low scores on PC1 exhibit higher rates of infant mortality (babymort), higher AIDS rates (aidsr), and higher birth rates (birthr). These are typical of less developed countries where healthcare and education systems are weaker and economic activity is lower.

- *Principal Component 2:* This component captures more demographic variables and aspects of population dynamics. Notably, countries with high scores on PC2 have higher death rates (deathr) and possibly lower population increases (popincr), indicating countries that may be experiencing either low birth rates, high mortality rates, or a combination of both. On the other end, countries with low scores on PC2 have higher fertility, birth rates (birthr), and a higher birth to death ratio (bdratio), suggesting these are countries with younger populations and potentially higher population growth due to these factors.

### d)

```{r}
#| label: fig-pca-01
#| fig-cap: Plot of principal component by region

world_complete = pca_cor |>
  augment(world_complete)

world_complete |> 
  ggplot() +
  geom_point(aes(x = .fittedPC1, y = .fittedPC2, color = region), size = 3) +
  xlab("PC1") +
  ylab("PC2") +
  scale_color_brewer(palette = "Dark2") +
  theme_classic()
```

Based on @fig-pca-01, there does appear to be an association between the component scores and the region a country belongs to. For instance:

-   OECD countries are generally clustered towards higher values on PC1. This suggests that OECD countries, which are typically more economically developed, have higher GDP, literacy rates, and life expectancy, characteristics that are positively correlated with PC1.

-   African countries are spread across both PC1 and PC2, but they are generally clustered towards lower PC1 values, indicating lower GDP, literacy rates, and life expectancy. The spread across PC2 might indicate variability in demographic patterns within the region, such as differences in birth and death rates.

-   Latin American, East European, Middle Eastern, and Pacific/Asian countries appear to be intermediate on PC1, which would suggest these regions have varying levels of development. They're not as high as OECD countries but not as low as many African countries.

-   Latin American countries show a slight trend towards lower values on PC2, which could imply higher birth rates and fertility rates in these countries.

-   East European countries seem to be more variable along PC2, which might reflect a diversity in demographic transitions, possibly due to the varying economic and historical contexts within this region.

-   Middle Eastern and Pacific/Asian countries are scattered across both components, indicating a wide variety of economic, health, and demographic profiles within these regions.

### e)

To show that the weight vectors for the first two components are orthogonal, we first need to extract the weight vectors or loadings for the perform analysis:

```{r}
#|code-fold: true
loadings = pca_cov$rotation
```

Then we check the dot product for the first two loadings vectors

```{r}
#| code-fold: false
round(sum(loadings[, 1] * loadings[, 2]), 3)
```

As expected, this value is $0$, showing that the weight or loadings for the first two components are orthogonal.

# Question 2

We read the data.

```{r}
wais = matrix(c(1.00, .37, .34, .40, .27, .59, .09, .25, .27, .22, .26,
 .37, 1.00, .27, .25, .38, .46, .10, .26, .29, .22, .24,
 .34, .27, 1.00, .36, .28, .33, .18, .32, .38, .29, .30,
 .40, .25, .36, 1.00, .22, .35, .08, .31, .26, .25, .20,
 .27, .38, .28, .22, 1.00, .29, .16, .14, .18, .15, .22,
 .59, .46, .33, .35, .29, 1.00, .08, .27, .24, .28, .26,
 .09, .10, .18, .08, .16, .08, 1.00, .19, .13, .22, .17,
 .25, .26, .32, .31, .14, .27, .19, 1.00, .36, .36, .40,
 .27, .29, .38, .26, .18, .24, .13, .36, 1.00, .30, .60, 
 .22, .22, .29, .25, .15, .28, .22, .36, .30, 1.00, .25,
 .26, .24, .30, .20, .22, .26, .17, .40, .60, .25, 1.00), 
ncol=11, byrow=T)

rownames(wais) = colnames(wais) = c("Information", "Comprehension", 
"Arithmetic", "Similarities", "Digit Span", "Vocabulary", "Digit Symbol", 
"Picture Completion", "Block Design", "Picture Arrangement", "Object 
Assembly") 
```

### a)

We perform a pca with the correlation matrix

```{r}
wais_pc = princomp(covmat = wais)
```

```{r}
#| label: fig-scree-plot-02
#| fig-cap: Scree plot
#| fig-width: 9
#| fig-height: 5

screeplot(wais_pc)
```

# Question 3
